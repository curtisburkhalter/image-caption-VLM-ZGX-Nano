from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from transformers import pipeline
import warnings
import io
from PIL import Image
import os
import logging

warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="VLM Image Captioning Demo")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files for frontend
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# Initialize the VLM pipeline
logger.info("Loading VLM model...")
try:
    image_to_text = pipeline("image-to-text", model="nlpconnect/vit-gpt2-image-captioning")
    logger.info("VLM model loaded successfully")
except Exception as e:
    logger.error(f"Error loading VLM model: {e}")
    image_to_text = None

@app.get("/", response_class=HTMLResponse)
async def read_root():
    """Serve the main HTML page"""
    try:
        with open("frontend/index.html", "r") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        return HTMLResponse(content="<h1>Frontend not found. Please ensure index.html exists in the frontend directory.</h1>", status_code=500)

@app.post("/api/analyze_images")
async def analyze_images(
    image1: UploadFile = File(...),
    image2: UploadFile = File(None)
):
    """
    Analyze one or two images and return captions generated by the VLM
    """
    if image_to_text is None:
        raise HTTPException(status_code=500, detail="VLM model not loaded")
    
    try:
        results = []
        
        # Process first image
        logger.info(f"Processing image 1: {image1.filename}")
        image1_data = await image1.read()
        img1 = Image.open(io.BytesIO(image1_data))
        
        # Generate caption for image 1
        result1 = image_to_text(img1)
        results.append({
            "image_number": 1,
            "filename": image1.filename,
            "caption": result1[0]['generated_text'] if result1 else "No caption generated"
        })
        logger.info(f"Image 1 caption: {results[0]['caption']}")
        
        # Process second image if provided
        if image2 and image2.filename:
            logger.info(f"Processing image 2: {image2.filename}")
            image2_data = await image2.read()
            img2 = Image.open(io.BytesIO(image2_data))
            
            # Generate caption for image 2
            result2 = image_to_text(img2)
            results.append({
                "image_number": 2,
                "filename": image2.filename,
                "caption": result2[0]['generated_text'] if result2 else "No caption generated"
            })
            logger.info(f"Image 2 caption: {results[1]['caption']}")
        
        return JSONResponse(content={
            "success": True,
            "results": results
        })
        
    except Exception as e:
        logger.error(f"Error processing images: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error processing images: {str(e)}")

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "model_loaded": image_to_text is not None
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
